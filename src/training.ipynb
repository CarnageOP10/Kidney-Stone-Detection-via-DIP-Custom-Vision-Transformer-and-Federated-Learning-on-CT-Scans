{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from visual_transformer import ConvNeXtViT\n",
    "from DIPutils import DIPTransform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset path\n",
    "dataset_path = r\"C:\\Users\\parth\\Downloads\\Kindey-Stone-Dataset\\Kindey-Stone-Dataset\\Augmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (resize, normalize, etc.)\n",
    "transform = transforms.Compose([\n",
    "    # DIPTransform(target_size=500),  # Apply DIP pipeline\n",
    "    # transforms.ToPILImage(),        # Convert back to PIL imagev\n",
    "    transforms.Resize((224, 224)),  # Resize to model input size\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 24821, Validation size: 5318, Test size: 5318\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset_path = dataset_path\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Define split sizes\n",
    "total_size = len(dataset)\n",
    "val_size = int(0.15 * total_size)  # 15% for validation\n",
    "test_size = int(0.15 * total_size)  # 15% for testing\n",
    "train_size = total_size - (val_size + test_size)  # Remaining 70% for training\n",
    "\n",
    "# Split dataset\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64 \n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_ds)}, Validation size: {len(val_ds)}, Test size: {len(test_ds)}\")\n",
    "# also print the number of classes\n",
    "num_classes = len(dataset.classes)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXtViT(\n",
      "  (convnext): ConvNeXt(\n",
      "    (stem): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (stages): Sequential(\n",
      "      (0): ConvNeXtStage(\n",
      "        (downsample): Identity()\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): ConvNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): ConvNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (5): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (6): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (7): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (8): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): ConvNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm_pre): Identity()\n",
      "    (head): NormMlpClassifierHead(\n",
      "      (global_pool): SelectAdaptivePool2d(pool_type=, flatten=Identity())\n",
      "      (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (flatten): Identity()\n",
      "      (pre_logits): Identity()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "      (fc): Identity()\n",
      "    )\n",
      "  )\n",
      "  (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (ffn): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=512, out_features=768, bias=True)\n",
      "  )\n",
      "  (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (dense1): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (classifier): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = ConvNeXtViT(input_shape=(224, 224, 3), num_classes=2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "def compute_accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return (preds == labels).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/20]\n",
      "Train Loss: 0.4504, Train Accuracy: 0.8556\n",
      "Val Loss: 0.3751, Val Accuracy: 0.9359\n",
      "\n",
      "Epoch [2/20]\n",
      "Train Loss: 0.3741, Train Accuracy: 0.9376\n",
      "Val Loss: 0.3582, Val Accuracy: 0.9543\n",
      "\n",
      "Epoch [3/20]\n",
      "Train Loss: 0.3610, Train Accuracy: 0.9515\n",
      "Val Loss: 0.3535, Val Accuracy: 0.9590\n",
      "\n",
      "Epoch [4/20]\n",
      "Train Loss: 0.3459, Train Accuracy: 0.9661\n",
      "Val Loss: 0.3518, Val Accuracy: 0.9603\n",
      "\n",
      "Epoch [5/20]\n",
      "Train Loss: 0.3518, Train Accuracy: 0.9608\n",
      "Val Loss: 0.3449, Val Accuracy: 0.9671\n",
      "\n",
      "Epoch [6/20]\n",
      "Train Loss: 0.3446, Train Accuracy: 0.9680\n",
      "Val Loss: 0.3419, Val Accuracy: 0.9716\n",
      "\n",
      "Epoch [7/20]\n",
      "Train Loss: 0.3368, Train Accuracy: 0.9759\n",
      "Val Loss: 0.3333, Val Accuracy: 0.9795\n",
      "\n",
      "Epoch [8/20]\n",
      "Train Loss: 0.3312, Train Accuracy: 0.9815\n",
      "Val Loss: 0.3328, Val Accuracy: 0.9799\n",
      "\n",
      "Epoch [9/20]\n",
      "Train Loss: 0.3392, Train Accuracy: 0.9739\n",
      "Val Loss: 0.3887, Val Accuracy: 0.9252\n",
      "\n",
      "Epoch [10/20]\n",
      "Train Loss: 0.3556, Train Accuracy: 0.9569\n",
      "Val Loss: 0.3338, Val Accuracy: 0.9788\n",
      "\n",
      "Epoch [11/20]\n",
      "Train Loss: 0.3300, Train Accuracy: 0.9830\n",
      "Val Loss: 0.3326, Val Accuracy: 0.9795\n",
      "\n",
      "Epoch [12/20]\n",
      "Train Loss: 0.3300, Train Accuracy: 0.9827\n",
      "Val Loss: 0.3422, Val Accuracy: 0.9688\n",
      "\n",
      "Epoch [13/20]\n",
      "Train Loss: 0.3278, Train Accuracy: 0.9854\n",
      "Val Loss: 0.3325, Val Accuracy: 0.9799\n",
      "\n",
      "Epoch [14/20]\n",
      "Train Loss: 0.3304, Train Accuracy: 0.9825\n",
      "Val Loss: 0.3364, Val Accuracy: 0.9761\n",
      "\n",
      "Epoch [15/20]\n",
      "Train Loss: 0.3396, Train Accuracy: 0.9735\n",
      "Val Loss: 0.3556, Val Accuracy: 0.9584\n",
      "\n",
      "Epoch [16/20]\n",
      "Train Loss: 0.3463, Train Accuracy: 0.9664\n",
      "Val Loss: 0.3427, Val Accuracy: 0.9697\n",
      "\n",
      "Epoch [17/20]\n",
      "Train Loss: 0.3360, Train Accuracy: 0.9769\n",
      "Val Loss: 0.3453, Val Accuracy: 0.9675\n",
      "\n",
      "Epoch [18/20]\n",
      "Train Loss: 0.3354, Train Accuracy: 0.9774\n",
      "Val Loss: 0.3424, Val Accuracy: 0.9699\n",
      "\n",
      "Epoch [19/20]\n",
      "Train Loss: 0.3278, Train Accuracy: 0.9852\n",
      "Val Loss: 0.3354, Val Accuracy: 0.9771\n",
      "\n",
      "Epoch [20/20]\n",
      "Train Loss: 0.3237, Train Accuracy: 0.9893\n",
      "Val Loss: 0.3321, Val Accuracy: 0.9808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20  # Set number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:  # Assume train_loader is your DataLoader\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients for validation\n",
    "        for val_inputs, val_labels in val_loader:  # Assume val_loader is your validation DataLoader\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_correct += (torch.argmax(val_outputs, dim=1) == val_labels).sum().item()\n",
    "            val_total += val_labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save teh model\n",
    "torch.save(model.state_dict(), 'model20.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3353, Test Accuracy: 0.9771\n"
     ]
    }
   ],
   "source": [
    "# test teh model\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct, total = 0, 0\n",
    "running_loss = 0.0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients for validation\n",
    "    for test_inputs, test_labels in test_loader:  # Assume val_loader is your validation DataLoader\n",
    "        test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "        test_outputs = model(test_inputs)\n",
    "        loss = criterion(test_outputs, test_labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        correct += (torch.argmax(test_outputs, dim=1) == test_labels).sum().item()\n",
    "        total += test_labels.size(0)\n",
    "test_loss = running_loss / len(test_loader)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
