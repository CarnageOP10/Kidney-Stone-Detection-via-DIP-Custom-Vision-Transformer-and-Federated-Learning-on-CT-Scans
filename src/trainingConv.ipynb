{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_transformer import ConvNeXtModel\n",
    "from DIPutils import DIPTransform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset path\n",
    "dataset_path = r\"C:\\Users\\parth\\Downloads\\Kindey-Stone-Dataset\\Kindey-Stone-Dataset\\Augmented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (resize, normalize, etc.)\n",
    "transform = transforms.Compose([\n",
    "    DIPTransform(target_size=500),  # Apply DIP pipeline\n",
    "    transforms.ToPILImage(),        # Convert back to PIL imagev\n",
    "    transforms.Resize((224, 224)),  # Resize to model input size\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 24821, Validation size: 5318, Test size: 5318\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset_path = dataset_path\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Define split sizes\n",
    "total_size = len(dataset)\n",
    "val_size = int(0.15 * total_size)  # 15% for validation\n",
    "test_size = int(0.15 * total_size)  # 15% for testing\n",
    "train_size = total_size - (val_size + test_size)  # Remaining 70% for training\n",
    "\n",
    "# Split dataset\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64 \n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_ds)}, Validation size: {len(val_ds)}, Test size: {len(test_ds)}\")\n",
    "# also print the number of classes\n",
    "num_classes = len(dataset.classes)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXtViT(\n",
      "  (convnext): ConvNeXt(\n",
      "    (stem): Sequential(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (stages): Sequential(\n",
      "      (0): ConvNeXtStage(\n",
      "        (downsample): Identity()\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "            (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): ConvNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "            (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): ConvNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (3): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (4): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (5): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (6): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (7): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (8): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "            (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): ConvNeXtStage(\n",
      "        (downsample): Sequential(\n",
      "          (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (1): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (2): ConvNeXtBlock(\n",
      "            (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "            (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (shortcut): Identity()\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm_pre): Identity()\n",
      "    (head): NormMlpClassifierHead(\n",
      "      (global_pool): SelectAdaptivePool2d(pool_type=, flatten=Identity())\n",
      "      (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (flatten): Identity()\n",
      "      (pre_logits): Identity()\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "      (fc): Identity()\n",
      "    )\n",
      "  )\n",
      "  (global_avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (attn): MultiheadAttention(\n",
      "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "  )\n",
      "  (ffn): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Linear(in_features=512, out_features=768, bias=True)\n",
      "  )\n",
      "  (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (dense1): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (classifier): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = ConvNeXtModel(input_shape=(224, 224, 3), num_classes=2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "def compute_accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return (preds == labels).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/20]\n",
      "Train Loss: 0.4504, Train Accuracy: 0.8556\n",
      "Val Loss: 0.3751, Val Accuracy: 0.9359\n",
      "\n",
      "Epoch [2/20]\n",
      "Train Loss: 0.3741, Train Accuracy: 0.9376\n",
      "Val Loss: 0.3582, Val Accuracy: 0.9543\n",
      "\n",
      "Epoch [3/20]\n",
      "Train Loss: 0.3610, Train Accuracy: 0.9515\n",
      "Val Loss: 0.3535, Val Accuracy: 0.9590\n",
      "\n",
      "Epoch [4/20]\n",
      "Train Loss: 0.3459, Train Accuracy: 0.9661\n",
      "Val Loss: 0.3518, Val Accuracy: 0.9603\n",
      "\n",
      "Epoch [5/20]\n",
      "Train Loss: 0.3518, Train Accuracy: 0.9608\n",
      "Val Loss: 0.3449, Val Accuracy: 0.9671\n",
      "\n",
      "Epoch [6/20]\n",
      "Train Loss: 0.3446, Train Accuracy: 0.9680\n",
      "Val Loss: 0.3419, Val Accuracy: 0.9716\n",
      "\n",
      "Epoch [7/20]\n",
      "Train Loss: 0.3368, Train Accuracy: 0.9759\n",
      "Val Loss: 0.3333, Val Accuracy: 0.9795\n",
      "\n",
      "Epoch [8/20]\n",
      "Train Loss: 0.3312, Train Accuracy: 0.9815\n",
      "Val Loss: 0.3328, Val Accuracy: 0.9799\n",
      "\n",
      "Epoch [9/20]\n",
      "Train Loss: 0.3392, Train Accuracy: 0.9739\n",
      "Val Loss: 0.3887, Val Accuracy: 0.9252\n",
      "\n",
      "Epoch [10/20]\n",
      "Train Loss: 0.3556, Train Accuracy: 0.9569\n",
      "Val Loss: 0.3338, Val Accuracy: 0.9788\n",
      "\n",
      "Epoch [11/20]\n",
      "Train Loss: 0.3300, Train Accuracy: 0.9830\n",
      "Val Loss: 0.3326, Val Accuracy: 0.9795\n",
      "\n",
      "Epoch [12/20]\n",
      "Train Loss: 0.3300, Train Accuracy: 0.9827\n",
      "Val Loss: 0.3422, Val Accuracy: 0.9688\n",
      "\n",
      "Epoch [13/20]\n",
      "Train Loss: 0.3278, Train Accuracy: 0.9854\n",
      "Val Loss: 0.3325, Val Accuracy: 0.9799\n",
      "\n",
      "Epoch [14/20]\n",
      "Train Loss: 0.3304, Train Accuracy: 0.9825\n",
      "Val Loss: 0.3364, Val Accuracy: 0.9761\n",
      "\n",
      "Epoch [15/20]\n",
      "Train Loss: 0.3396, Train Accuracy: 0.9735\n",
      "Val Loss: 0.3556, Val Accuracy: 0.9584\n",
      "\n",
      "Epoch [16/20]\n",
      "Train Loss: 0.3463, Train Accuracy: 0.9664\n",
      "Val Loss: 0.3427, Val Accuracy: 0.9697\n",
      "\n",
      "Epoch [17/20]\n",
      "Train Loss: 0.3360, Train Accuracy: 0.9769\n",
      "Val Loss: 0.3453, Val Accuracy: 0.9675\n",
      "\n",
      "Epoch [18/20]\n",
      "Train Loss: 0.3354, Train Accuracy: 0.9774\n",
      "Val Loss: 0.3424, Val Accuracy: 0.9699\n",
      "\n",
      "Epoch [19/20]\n",
      "Train Loss: 0.3278, Train Accuracy: 0.9852\n",
      "Val Loss: 0.3354, Val Accuracy: 0.9771\n",
      "\n",
      "Epoch [20/20]\n",
      "Train Loss: 0.3237, Train Accuracy: 0.9893\n",
      "Val Loss: 0.3321, Val Accuracy: 0.9808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20  # Set number of epochs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for inputs, labels in train_loader:  # Assume train_loader is your DataLoader\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (torch.argmax(outputs, dim=1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_correct, val_total = 0, 0\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients for validation\n",
    "        for val_inputs, val_labels in val_loader:  # Assume val_loader is your validation DataLoader\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_correct += (torch.argmax(val_outputs, dim=1) == val_labels).sum().item()\n",
    "            val_total += val_labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save teh model\n",
    "torch.save(model.state_dict(), 'model20.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3294, Test Accuracy: 0.9853\n"
     ]
    }
   ],
   "source": [
    "# test teh model\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct, total = 0, 0\n",
    "running_loss = 0.0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients for validation\n",
    "    for test_inputs, test_labels in test_loader:  # Assume val_loader is your validation DataLoader\n",
    "        test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n",
    "        test_outputs = model(test_inputs)\n",
    "        loss = criterion(test_outputs, test_labels)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        correct += (torch.argmax(test_outputs, dim=1) == test_labels).sum().item()\n",
    "        total += test_labels.size(0)\n",
    "test_loss = running_loss / len(test_loader)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on test data and return metrics\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        test_loader: DataLoader with test data\n",
    "        device: 'cuda' or 'cpu'\n",
    "    Returns:\n",
    "        Dictionary containing metrics and confusion matrix\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    recall = recall_score(all_labels, all_preds, average='binary')  # for 2 classes\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary')\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return {\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.9718\n",
      "F1 Score: 0.9843\n",
      "Confusion Matrix:\n",
      "[[2792    7]\n",
      " [  71 2448]]\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {metrics['f1_score']:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(metrics['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcgAAAHACAYAAAAm8viHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxyUlEQVR4nO3df3zN9f//8fvZ2DE/Nob9evuRUn6UpOnNKgp7mx9vWbyTIlN+vGlTLD9aP1B6t6Leosi7H5qK0luRprAmFubXaoXwQWq8OUPY2nA22/n+0bfT+7y99Np0OOx1u14ur8ul83o9z2vPc8J9j8d5vl7H5nK5XAIAAB78fD0BAAAuRQQkAAAGCEgAAAwQkAAAGCAgAQAwQEACAGCAgAQAwAABCQCAAQISAAADVXw9gQshsE2ir6cAizi++RVfTwEWUc3L/1p789/JU19Xzr8HlTIgAQAmbDQQzfAOAQBggAoSAKzIZvP1DC55BCQAWBEtVlO8QwAAGKCCBAArosVqioAEACuixWqKdwgAAANUkABgRbRYTRGQAGBFtFhN8Q4BAGCAChIArIgWqykCEgCsiBarKd4hAAAMUEECgBXRYjVFQAKAFdFiNcU7BACAASpIALAiWqymCEgAsCJarKZ4hwAAMEAFCQBWRAVpioAEACvy4zNIM/wKAQCAASpIALAiWqymCEgAsCIu8zDFrxAAABigggQAK6LFaoqABAArosVqil8hAAAwQAUJAFZEi9UUAQkAVkSL1RS/QgAAYIAKEgCsiBarKQISAKyIFqspfoUAAMAAAQkAVmTz895WASkpKbrppptUq1YthYaGKi4uTrt27fIYc/vtt8tms3lsI0aM8BiTm5urnj17qnr16goNDdW4ceN05swZjzGrV6/WjTfeKLvdrqZNmyo1NbVCcyUgAcCKbDbvbRWwZs0aJSQkaMOGDUpPT1dJSYm6du2qoqIij3HDhg3ToUOH3NvUqVPdx0pLS9WzZ08VFxdr/fr1mjdvnlJTUzVx4kT3mH379qlnz57q1KmTcnJyNHr0aA0dOlQrVqwo91z5DBIAcNEsX77c43FqaqpCQ0OVnZ2tjh07uvdXr15d4eHhhudYuXKlvvvuO33++ecKCwvTDTfcoClTpmjChAmaPHmyAgICNGfOHDVp0kQvvviiJKlFixZau3atpk+frtjY2HLNlQoSAKzIiy1Wp9OpgoICj83pdJZrGvn5+ZKkkJAQj/3z589XvXr1dN111yk5OVknT550H8vKylKrVq0UFhbm3hcbG6uCggJt377dPSYmJsbjnLGxscrKyir3W0RAAoAVeTEgU1JSFBwc7LGlpKSYTqGsrEyjR4/WLbfcouuuu869/95779W7776rL774QsnJyXrnnXc0cOBA93GHw+ERjpLcjx0Ox++OKSgo0KlTp8r1FtFiBQD8IcnJyUpKSvLYZ7fbTZ+XkJCgbdu2ae3atR77hw8f7v7vVq1aKSIiQl26dNHevXt11VVXeWfS5UBAAoAVefE6SLvdXq5A/G+JiYlKS0tTZmamGjRo8Ltj27VrJ0nas2ePrrrqKoWHh2vTpk0eY/Ly8iTJ/blleHi4e99/jwkKClJgYGC55kiLFQCsyEeXebhcLiUmJmrx4sVatWqVmjRpYvqcnJwcSVJERIQkKTo6Wlu3btXhw4fdY9LT0xUUFKSWLVu6x2RkZHicJz09XdHR0eWeKwEJALhoEhIS9O6772rBggWqVauWHA6HHA6H+3PBvXv3asqUKcrOztYPP/ygpUuXatCgQerYsaOuv/56SVLXrl3VsmVL3Xffffrmm2+0YsUKPfHEE0pISHBXsiNGjND333+v8ePHa+fOnZo9e7Y++OADjRkzptxztblcLpf33wLfCmyT6OspwCKOb37F11OARVTz8gdigXGvee1cp5YMNx/0/9nO0dp96623NHjwYO3fv18DBw7Utm3bVFRUpIYNG+rOO+/UE088oaCgIPf4H3/8USNHjtTq1atVo0YNxcfH67nnnlOVKr+9UatXr9aYMWP03XffqUGDBnryySc1ePDg8s+VgATOHwGJi8XrAXnnG14716nFQ712rksJLVYAAAywihUArIhv8zBFQAKABZ3rs0D8hhYrAAAGqCABwIKoIM0RkABgReSjKVqsAAAYoIIEAAuixWqOgAQACyIgzdFiBQDAABUkAFgQFaQ5AhIALIiANEeLFQAAA1SQAGBFFJCmCEgAsCBarOZosQIAYIAKEgAsiArSHAEJABZEQJqjxQoAgAEqSACwICpIcwQkAFgR+WiKFisAAAaoIAHAgmixmiMgAcCCCEhztFgBADBABQkAFkQFaY6ABAArIh9N0WIFAMAAFSQAWBAtVnMEJABYEAFpjhYrAAAGqCABwIKoIM0RkABgQQSkOVqsAAAYoIIEACuigDRFQAKABdFiNUeLFQAAA1SQAGBBVJDmCEgAsCAC0hwtVgAADFBBAoAVUUCaIiABwIJosZqjxQoAgAEqyEpi7ANdFde5ta65IkynnCXa+M33enzGx9r942FJUqOIEO369GnD5w4Y96Y++vxrSdLtf75Gkx78q65tGqmiU8Wa/8lGTZr1iUpLyyRJHaKu1qiBndT22sYKqllNe3KP6KV5n+v9z7ZcnBeKy1b3v3TWwYP/OWv/3f3v1WNPTvLBjKyNCtIcAVlJdLixqeYszFT29h9VpYq/nkrspbRXE9WmzzM6ebpYB/KO64qYZI/nPND3Fo0ZFKMV67ZLklpd8ycteXmknn9zhYY8+bYiQ2vr5cf6y9/fT8nTF0uS2rduom27/6N/pqYr76ef1aPDdXpjyiDlF57WZ19uu+ivG5eP+QsXqay01P14z57d+vvQ+/WX2G4+nJV1EZDmCMhKonfibI/Hwye9q/2rnlOblg217qu9KitzKe+nnz3G3NGptT5M/0pFp4olSX/reqO27T6olNeWS5K+339Uj89Yoneff0D/+NenKjzp1LS5Kz3OMeu91eoS3Vy9O7cmIPG7QkJCPB7PfeM1NWzYSG1v+rOPZgT8Pj6DrKSCalaTJB3PP2l4vE2LhrqheUPNW5Ll3mcPqKLTzhKPcaecJQqsFqA2LRqd82cF1wzU8QLjnwMYKSku1rK0pYrr05dKxkdsNpvXtsrKpxXk0aNHNXfuXGVlZcnhcEiSwsPDdfPNN2vw4MGqX7++L6d32bLZbJo29m9a//Vefbf3kOGY+Lho7fj+kDZ8s8+9L339DiXe20n9ukVp0cqvFF43SI8N7y5JiqgfZHievn9po6hrGynxmfe8/0JQaa1a9bl+/vln3RF3p6+nYl2VN9e8xmcV5ObNm3XNNddo5syZCg4OVseOHdWxY0cFBwdr5syZat68ubZsMV/44XQ6VVBQ4LG5ykpNn1eZvZTcT9c2jdCgR98yPF7NXlV3d2/rUT1KUsaGnXrspSWa+Vh/5W98Sd9+PFEr1v7y+WRZmeus83Rse7X+9dRAPTjlPe343uH9F4JKa/GHH+qWWzsqNDTM11MBzslnFeSoUaN01113ac6cOWeV6C6XSyNGjNCoUaOUlZV1jjP8IiUlRU899ZTHPv+wm1Q1wpqfa0yfcJd6dLhOMUNe0n8OnzAcc2fMDapeLUDz0zaddWzmu6s0891ViqgfrOMFJ9U4MkRTHuqtfQeOeoy7NaqpPpwxQuNf+EgLDM4DnMvBg//Rxg3r9c8ZL/t6KpZWmVuj3uKzCvKbb77RmDFjDP8n2Ww2jRkzRjk5OabnSU5OVn5+vsdWJSzqAsz40jd9wl26o3Nrdfv7TP148Kdzjhscd7OWrdmqo8cLzznm0JF8nXaWqF+3ttp/6Ji+3rnffaxD1NVaPHOknpjxseZ+tM6rrwGV38eLP1JISF116Hi7r6diaXwGac5nFWR4eLg2bdqk5s2bGx7ftGmTwsLM2y92u112u91jn83P3ytzvJy8lNxPd3dvq7vGvKbCotMKq1tLkpRfeNpj4c2VDevp1huvUtyoVw3PM2ZQF61cv0NlZWXq3eUGjb3/Lxo4fq67xdqx7dX6aOYIzVqwWksyvnb/nOKSUhbqwFRZWZk+XvyRevWOU5UqLKLHpc1nf0LHjh2r4cOHKzs7W126dHGHYV5enjIyMvT666/rhRde8NX0Ljt/79dRkpT+xmiP/cMmvqN3P9nofhzfO1r/yTuhz7N2Gp6n6y0tNX5orOxVq2jr//1Hd415TSvXfec+PrBXO9UItGv8kFiNHxLr3p+5Zbdih83w4itCZbQha70OHTqouD59fT0Vy6vEhZ/X2Fwu19mrLy6ShQsXavr06crOzlbp/7+A2N/fX1FRUUpKSlK/fv3O67yBbRK9OU3gnI5vfsXXU4BFVPNyOXP1uOVeO9fuaZXzZg8+7XHcfffduvvuu1VSUqKjR39ZBFKvXj1VrVrVl9MCAODSuJNO1apVFRER4etpAIBl0GI1d0kEJADg4qrMq0+9hVvNAQBggIAEAAuy2by3VURKSopuuukm1apVS6GhoYqLi9OuXbs8xpw+fVoJCQmqW7euatasqb59+yovL89jTG5urnr27Knq1asrNDRU48aN05kzZzzGrF69WjfeeKPsdruaNm2q1NTUCs2VgAQAC/Lzs3ltq4g1a9YoISFBGzZsUHp6ukpKStS1a1cVFRW5x4wZM0affPKJ/v3vf2vNmjU6ePCg+vTp4z5eWlqqnj17qri4WOvXr9e8efOUmpqqiRMnusfs27dPPXv2VKdOnZSTk6PRo0dr6NChWrFiRbnn6tPLPC4ULvPAxcJlHrhYvH2ZR8vHVpoPKqfvnu163s89cuSIQkNDtWbNGnXs2FH5+fmqX7++FixYoL/97W+SpJ07d6pFixbKyspS+/bt9dlnn+mvf/2rDh486L6Gfs6cOZowYYKOHDmigIAATZgwQcuWLdO2bb99DV///v114sQJLV9evktcqCABwIK82WI1+tIIp9NZrnnk5+dL+u37QrOzs1VSUqKYmBj3mObNm6tRo0bue3NnZWWpVatWHndbi42NVUFBgbZv3+4e89/n+HWM2f29/xsBCQD4Q1JSUhQcHOyxpaSkmD6vrKxMo0eP1i233KLrrrtOkuRwOBQQEKDatWt7jA0LC3N/LaLD4TjrVqS/PjYbU1BQoFOnTpXrdXGZBwBYkDcv80hOTlZSUpLHvv+9R7aRhIQEbdu2TWvXrvXaXLyJgAQAC/LmZZBGXxphJjExUWlpacrMzFSDBg3c+8PDw1VcXKwTJ054VJF5eXkKDw93j9m0yfNr9n5d5frfY/535WteXp6CgoIUGBhYrjnSYgUAXDQul0uJiYlavHixVq1apSZNmngcj4qKUtWqVZWRkeHet2vXLuXm5io6OlqSFB0dra1bt+rw4cPuMenp6QoKClLLli3dY/77HL+O+fUc5UEFCQAW5Ks76SQkJGjBggX6+OOPVatWLfdnhsHBwQoMDFRwcLCGDBmipKQkhYSEKCgoSKNGjVJ0dLTat28vSeratatatmyp++67T1OnTpXD4dATTzyhhIQEdyU7YsQIvfLKKxo/frweeOABrVq1Sh988IGWLVtW7rkSkABgQb4KyFdf/eW7aG+//XaP/W+99ZYGDx4sSZo+fbr8/PzUt29fOZ1OxcbGavbs2e6x/v7+SktL08iRIxUdHa0aNWooPj5eTz/9tHtMkyZNtGzZMo0ZM0YzZsxQgwYN9MYbbyg2NlblxXWQwB/AdZC4WLx9HWTrSRnmg8rpm6e6eO1clxIqSACwIO5Vbo6ABAAL4ts8zLGKFQAAA1SQAGBBFJDmCEgAsCBarOZosQIAYIAKEgAsiALSHAEJABZEi9UcLVYAAAxQQQKABVFAmiMgAcCCaLGao8UKAIABKkgAsCAKSHMEJABYEC1Wc7RYAQAwQAUJABZEAWmOgAQAC6LFao4WKwAABqggAcCCKCDNEZAAYEG0WM3RYgUAwAAVJABYEBWkOQISACyIfDRHixUAAANUkABgQbRYzRGQAGBB5KM5WqwAABigggQAC6LFao6ABAALIh/N0WIFAMAAFSQAWJAfJaQpAhIALIh8NEeLFQAAA1SQAGBBrGI1R0ACgAX5kY+maLECAGCAChIALIgWqzkCEgAsiHw0R4sVAAADVJAAYEE2UUKaISABwIJYxWqOFisAAAaoIAHAgljFao6ABAALIh/N0WIFAMAAFSQAWBBfd2WOgAQACyIfzdFiBQDAABUkAFgQq1jNEZAAYEHkozlarAAAGKCCBAALYhWrOQISACyIeDRHixUAAANUkABgQaxiNUdAAoAF8XVX5mixAgBgoFwV5NKlS8t9wjvuuOO8JwMAuDhosZorV0DGxcWV62Q2m02lpaV/ZD4AgIvAV/mYmZmpadOmKTs7W4cOHdLixYs9Mmbw4MGaN2+ex3NiY2O1fPly9+Njx45p1KhR+uSTT+Tn56e+fftqxowZqlmzpnvMt99+q4SEBG3evFn169fXqFGjNH78+ArNtVwt1rKysnJthCMA4PcUFRWpdevWmjVr1jnHdOvWTYcOHXJv7733nsfxAQMGaPv27UpPT1daWpoyMzM1fPhw9/GCggJ17dpVjRs3VnZ2tqZNm6bJkyfrtddeq9BcWaQDABbkqxZr9+7d1b17998dY7fbFR4ebnhsx44dWr58uTZv3qy2bdtKkl5++WX16NFDL7zwgiIjIzV//nwVFxdr7ty5CggI0LXXXqucnBz985//9AhSM+cVkEVFRVqzZo1yc3NVXFzsceyhhx46n1MCAC4ib65idTqdcjqdHvvsdrvsdvt5nW/16tUKDQ1VnTp11LlzZz3zzDOqW7euJCkrK0u1a9d2h6MkxcTEyM/PTxs3btSdd96prKwsdezYUQEBAe4xsbGxev7553X8+HHVqVOnXPOocEB+/fXX6tGjh06ePKmioiKFhITo6NGjql69ukJDQwlIALCYlJQUPfXUUx77Jk2apMmTJ1f4XN26dVOfPn3UpEkT7d27V4899pi6d++urKws+fv7y+FwKDQ01OM5VapUUUhIiBwOhyTJ4XCoSZMmHmPCwsLcxy5YQI4ZM0a9evXSnDlzFBwcrA0bNqhq1aoaOHCgHn744YqeDgDgA95ssSYnJyspKclj3/lWj/3793f/d6tWrXT99dfrqquu0urVq9WlS5c/NM+KqvB1kDk5OXrkkUfk5+cnf39/OZ1ONWzYUFOnTtVjjz12IeYIAPAymxc3u92uoKAgj+18A/J/XXnllapXr5727NkjSQoPD9fhw4c9xpw5c0bHjh1zf24ZHh6uvLw8jzG/Pj7XZ5tGKhyQVatWlZ/fL08LDQ1Vbm6uJCk4OFj79++v6OkAADinAwcO6KefflJERIQkKTo6WidOnFB2drZ7zKpVq1RWVqZ27dq5x2RmZqqkpMQ9Jj09Xc2aNSt3e1U6j4Bs06aNNm/eLEm67bbbNHHiRM2fP1+jR4/WddddV9HTAQB8wM9m89pWEYWFhcrJyVFOTo4kad++fcrJyVFubq4KCws1btw4bdiwQT/88IMyMjLUu3dvNW3aVLGxsZKkFi1aqFu3bho2bJg2bdqkdevWKTExUf3791dkZKQk6d5771VAQICGDBmi7du3a+HChZoxY8ZZbWDT96hCoyU9++yz7iT/xz/+oTp16mjkyJE6cuRIha8xAQD4hs3mva0itmzZojZt2qhNmzaSpKSkJLVp00YTJ06Uv7+/vv32W91xxx265pprNGTIEEVFRenLL7/0aNnOnz9fzZs3V5cuXdSjRw/deuutHvkTHByslStXat++fYqKitIjjzyiiRMnVugSD0myuVwuV8Ve3qUvsE2ir6cAizi++RVfTwEWUc3LV60P+2Cb1871er/K2T3kRgEAYEHci9VchQOySZMmv/vGfv/9939oQgCAC498NFfhgBw9erTH45KSEn399ddavny5xo0b5615AQDgUxUOyHPdDGDWrFnasmXLH54QAODCq+jqUyvy2hcmd+/eXR9++KG3TgcAuIB8tYr1cuK1gFy0aJFCQkK8dToAAHyqwi3WNm3aeCzScblccjgcOnLkiGbPnu3VyQEALgxWsZqrcED27t3b44318/NT/fr1dfvtt6t58+Zendz5OrLhZV9PARZR5643fD0FWMSpxUO9ej6vtQ8rsQoH5Pl8fQkAAJebCv8S4e/vf9ad1CXpp59+kr+/v1cmBQC4sGw2m9e2yqrCFeS57kzndDo9vr0ZAHDp8qu8ueY15Q7ImTNnSvrlt4433nhDNWvWdB8rLS1VZmbmJfMZJAAAf1S5A3L69OmSfqkg58yZ49FODQgI0BVXXKE5c+Z4f4YAAK+jgjRX7oDct2+fJKlTp0766KOPKvSlkwCAS0tl/uzQWyr8GeQXX3xxIeYBAMAlpcKrWPv27avnn3/+rP1Tp07VXXfd5ZVJAQAuLD+b97bKqsIBmZmZqR49epy1v3v37srMzPTKpAAAFxb3YjVX4YAsLCw0vJyjatWqKigo8MqkAADwtQoHZKtWrbRw4cKz9r///vtq2bKlVyYFALiw/Gw2r22VVYUX6Tz55JPq06eP9u7dq86dO0uSMjIytGDBAi1atMjrEwQAeB/3YjVX4YDs1auXlixZomeffVaLFi1SYGCgWrdurVWrVvF1VwCASqPCASlJPXv2VM+ePSVJBQUFeu+99zR27FhlZ2ertLTUqxMEAHhfJe6Mes15V9mZmZmKj49XZGSkXnzxRXXu3FkbNmzw5twAABcIn0Gaq1AF6XA4lJqaqjfffFMFBQXq16+fnE6nlixZwgIdAEClUu4KslevXmrWrJm+/fZbvfTSSzp48KBefpkvJgaAyxHXQZordwX52Wef6aGHHtLIkSN19dVXX8g5AQAusMp8BxxvKXcFuXbtWv3888+KiopSu3bt9Morr+jo0aMXcm4AAPhMuQOyffv2ev3113Xo0CH9/e9/1/vvv6/IyEiVlZUpPT1dP//884WcJwDAi1ikY67Cq1hr1KihBx54QGvXrtXWrVv1yCOP6LnnnlNoaKjuuOOOCzFHAICX8RmkuT90M4VmzZpp6tSpOnDggN577z1vzQkAAJ87rxsF/C9/f3/FxcUpLi7OG6cDAFxgLNIx55WABABcXmwiIc1wv1oAAAxQQQKABdFiNUdAAoAFEZDmaLECAGCAChIALMhWmS9g9BICEgAsiBarOVqsAAAYoIIEAAuiw2qOgAQAC6rMNxn3FlqsAAAYoIIEAAtikY45AhIALIgOqzlarAAAGKCCBAAL8uPbPEwRkABgQbRYzdFiBQDAABUkAFgQq1jNEZAAYEHcKMAcLVYAAAxQQQKABVFAmiMgAcCCaLGao8UKAIABKkgAsCAKSHMEJABYEO1Dc7xHAAAYoIIEAAuy0WM1RQUJABZk8+JWEZmZmerVq5ciIyNls9m0ZMkSj+Mul0sTJ05URESEAgMDFRMTo927d3uMOXbsmAYMGKCgoCDVrl1bQ4YMUWFhoceYb7/9Vh06dFC1atXUsGFDTZ06tYIzJSABABdRUVGRWrdurVmzZhkenzp1qmbOnKk5c+Zo48aNqlGjhmJjY3X69Gn3mAEDBmj79u1KT09XWlqaMjMzNXz4cPfxgoICde3aVY0bN1Z2dramTZumyZMn67XXXqvQXG0ul8t1fi/z0lXorHQvCZeo+v3f9PUUYBGnFg/16vnezT7gtXMNjGpwXs+z2WxavHix4uLiJP1SPUZGRuqRRx7R2LFjJUn5+fkKCwtTamqq+vfvrx07dqhly5bavHmz2rZtK0lavny5evTooQMHDigyMlKvvvqqHn/8cTkcDgUEBEiSHn30US1ZskQ7d+4s9/yoIAHAgrzZYnU6nSooKPDYnE5nhee0b98+ORwOxcTEuPcFBwerXbt2ysrKkiRlZWWpdu3a7nCUpJiYGPn5+Wnjxo3uMR07dnSHoyTFxsZq165dOn78eLnnQ0ACAP6QlJQUBQcHe2wpKSkVPo/D4ZAkhYWFeewPCwtzH3M4HAoNDfU4XqVKFYWEhHiMMTrHf/+M8mAVKwBYkDcXsSYnJyspKcljn91u994P8BECEgAsyJuXedjtdq8EYnh4uCQpLy9PERER7v15eXm64YYb3GMOHz7s8bwzZ87o2LFj7ueHh4crLy/PY8yvj38dUx60WAEAl4QmTZooPDxcGRkZ7n0FBQXauHGjoqOjJUnR0dE6ceKEsrOz3WNWrVqlsrIytWvXzj0mMzNTJSUl7jHp6elq1qyZ6tSpU+75EJAAYEF+XtwqorCwUDk5OcrJyZH0y8KcnJwc5ebmymazafTo0XrmmWe0dOlSbd26VYMGDVJkZKR7pWuLFi3UrVs3DRs2TJs2bdK6deuUmJio/v37KzIyUpJ07733KiAgQEOGDNH27du1cOFCzZgx46w2sBlarABgQb66k86WLVvUqVMn9+NfQys+Pl6pqakaP368ioqKNHz4cJ04cUK33nqrli9frmrVqrmfM3/+fCUmJqpLly7y8/NT3759NXPmTPfx4OBgrVy5UgkJCYqKilK9evU0ceJEj2sly4PrIIE/gOsgcbF4+zrID3IOeu1c/W6I9Nq5LiVUkABgQdyJ1RwBCQAWxM3KzbFIBwAAA1SQAGBBVEfmCEgAsCBarOb4JQIAAANUkABgQdSP5ghIALAgOqzmaLECAGCAChIALMiPJqspAhIALIgWqzlarAAAGKCCBAALstFiNUVAAoAF0WI1R4sVAAADVJAAYEGsYjVHQAKABdFiNUeLFQAAA1SQAGBBVJDmCEgAsCAu8zBHixUAAANUkABgQX4UkKYISACwIFqs5mixAgBggAoSACyIVazmCEgAsCBarOZosQIAYIAKEgAsiFWs5ghIALAgWqzmCEgL+Wu3zjp08OBZ+++6+149+vhEfbRooZZ/mqadO75TUVGRVq/dpFpBQT6YKS5lY/u0Vlz7K3RNg2CdKi7Vxp15evztzdp9MN9w/JInYxV7Y0P1S0nXJ5t+POt4SC27Nv2zj/5Ur4bCB7yt/JPF7mP9O16lMXHXq2lksPKLirXy6/16bN4mHfvZecFeH/ArPoO0kHcWLNKKVV+6t9mvzZUkxXSNlSSdPnVa0bd00P1D/+7LaeIS1+HacM357DvdNmGp/jr5M1Xx91PapG6qbj/79+1Rva6Ty/X755uT0EFbfzx21v7o5mF646HbNC/j/3TjQ4s08IUMtb26vmY/2MFbL8XSbDbvbZUVFaSF1AkJ8Xic+ubratCwkaLa/lmSdO998ZKkLZs3XvS54fLRe8oKj8fDX87U/nkD1eaqelr3ncO9//orQvTwHa10y7gl+uGtAYbnGhbbQsE17Hr2g6/ULaqhx7F2zUL145FCzV62XZL04+FCvblipx65s7WXX5E1VeJc8xoqSIsqKSnWp8uWqndcH9kq86+AuOCCqgdIko4X/tb2DAzwV2pSJ41+fZ3yTpwyfF7zBrWV3K+Nhs5YrbKys49v3HVYDerWUOyNDSRJocGBuvPmJlr+1X7vvwjAwCVdQe7fv1+TJk3S3LlzzznG6XTK6fT8PKJEAbLb7Rd6epe1L1ZlqPDnn9Wr952+ngouYzabNG1Ie63f4dB3ucfd+6c+0F4bdh5W2qZcw+cFVPHTvKROeuztTdp/tEhXhJ39WXfWzjzd/9JqvTO2s6pVraKqVfyUtulHjX5t3QV7PVbixy/Gpi7pCvLYsWOaN2/e745JSUlRcHCwx/bi1JSLNMPL18eLF+nmWzqofmiYr6eCy9hLw2/RtY3qaNCLq9z7et7USLe3itS4uVnnfN6U+27SrgMn9P6aPecc07xBbb0wpL1SPvhaN49dol5PfabGobX08ohbvfoarMrmxa2y8mkFuXTp0t89/v3335ueIzk5WUlJSR77ShTwh+ZV2R06+B9t2pCladNf9vVUcBmbPixaPdo2VMzjafrPTyfd+29vFakrw4PkeHeQx/j3xnfRuh15in1ymW5rFanrGtXRnTc3kfTbP7IH3h6o5xfl6Jn3v9K4vq2VtTNP05dslSRt+1E66VynjGd76akFW+Q4bty6BbzFpwEZFxcnm80m1+8sczP7fMxut5/VTi10miybs7ilSz5SnZC6urXDbb6eCi5T04dF6452V6jrk8v04+FCj2MvfPSN3vp8l8e+7Bl9Nf6tjVq2+ZfLPO6Z+rkCA3775yeqaT29Nuo2xTyepu8dBZKk6vYqOlPq+Xe5tOyXx1zD5wW8haZ8GpARERGaPXu2evfubXg8JydHUVFRF3lWlVtZWZmWfrxYf70jTlWqeP7vP3r0iH46elT7c3/53GjP7v9T9Ro1FB4RoeDg2j6YLS5FLw2/WXd3vEp3paSr8FSJwmoHSpLyTxbrdHGp8k6cMlyYs/9IoTtM9zl+9jhWt1Y1SdLO/Sfc10Eu25yr2Q920LDYFkrPOaCIOtU17YH22vx/h3Xo+Enhj+GXDHM+DcioqChlZ2efMyDNqktU3MYN6+U4dFC94/qcdezDD97Xa3NmuR8PvX+gJGnSlGd1R++zx8Oa/t69pSQp/Zm/euwfNnON3v1it9d+zrtf7FatwKoa0aOlnru/nfKLnFq99ZCeeHuT134G8HtsLh8m0JdffqmioiJ169bN8HhRUZG2bNmi226rWCuQFisulvr93/T1FGARpxYP9er5Nn1vfOej8/HnK4O9dq5LiU8ryA4dfv+OGDVq1KhwOAIAzNFgNXdJX+YBAICvXNI3CgAAXCCUkKYISACwIFaxmqPFCgCAASpIALAgbsVqjgoSAAADVJAAYEEUkOYISACwIhLSFC1WAAAMUEECgAVxmYc5AhIALIhVrOZosQIAYIAKEgAsiALSHAEJAFZEQpqixQoAgAEqSACwIFaxmiMgAcCCWMVqjhYrAOCimTx5smw2m8fWvHlz9/HTp08rISFBdevWVc2aNdW3b1/l5eV5nCM3N1c9e/ZU9erVFRoaqnHjxunMmTNenysVJABYkC8LyGuvvVaff/65+3GVKr9F0ZgxY7Rs2TL9+9//VnBwsBITE9WnTx+tW7dOklRaWqqePXsqPDxc69ev16FDhzRo0CBVrVpVzz77rFfnSUACgBX5MCGrVKmi8PDws/bn5+frzTff1IIFC9S5c2dJ0ltvvaUWLVpow4YNat++vVauXKnvvvtOn3/+ucLCwnTDDTdoypQpmjBhgiZPnqyAgACvzZMWKwDgotq9e7ciIyN15ZVXasCAAcrNzZUkZWdnq6SkRDExMe6xzZs3V6NGjZSVlSVJysrKUqtWrRQWFuYeExsbq4KCAm3fvt2r86SCBAAL8uYqVqfTKafT6bHPbrfLbrefNbZdu3ZKTU1Vs2bNdOjQIT311FPq0KGDtm3bJofDoYCAANWuXdvjOWFhYXI4HJIkh8PhEY6/Hv/1mDdRQQKABdls3ttSUlIUHBzssaWkpBj+3O7du+uuu+7S9ddfr9jYWH366ac6ceKEPvjgg4v8DpgjIAEAf0hycrLy8/M9tuTk5HI9t3bt2rrmmmu0Z88ehYeHq7i4WCdOnPAYk5eX5/7MMjw8/KxVrb8+Nvpc848gIAHAgmxe3Ox2u4KCgjw2o/aqkcLCQu3du1cRERGKiopS1apVlZGR4T6+a9cu5ebmKjo6WpIUHR2trVu36vDhw+4x6enpCgoKUsuWLf/AO3I2PoMEACvy0SrWsWPHqlevXmrcuLEOHjyoSZMmyd/fX/fcc4+Cg4M1ZMgQJSUlKSQkREFBQRo1apSio6PVvn17SVLXrl3VsmVL3XfffZo6daocDoeeeOIJJSQklDuUy4uABABcNAcOHNA999yjn376SfXr19ett96qDRs2qH79+pKk6dOny8/PT3379pXT6VRsbKxmz57tfr6/v7/S0tI0cuRIRUdHq0aNGoqPj9fTTz/t9bnaXC6Xy+tn9bFCZ6V7SbhE1e//pq+nAIs4tXioV8+389BJr52reUR1r53rUkIFCQAWxL1YzbFIBwAAA1SQAGBBFJDmCEgAsCIS0hQtVgAADFBBAoAFefNerJUVAQkAFsQqVnO0WAEAMEAFCQAWRAFpjoAEACsiIU3RYgUAwAAVJABYEKtYzRGQAGBBrGI1R4sVAAADVJAAYEEUkOYISACwIhLSFC1WAAAMUEECgAWxitUcAQkAFsQqVnO0WAEAMEAFCQAWRAFpjoAEAAuixWqOFisAAAaoIAHAkighzRCQAGBBtFjN0WIFAMAAFSQAWBAFpDkCEgAsiBarOVqsAAAYoIIEAAviXqzmCEgAsCLy0RQtVgAADFBBAoAFUUCaIyABwIJYxWqOFisAAAaoIAHAgljFao6ABAArIh9N0WIFAMAAFSQAWBAFpDkCEgAsiFWs5mixAgBggAoSACyIVazmCEgAsCBarOZosQIAYICABADAAC1WALAgWqzmqCABADBABQkAFsQqVnMEJABYEC1Wc7RYAQAwQAUJABZEAWmOgAQAKyIhTdFiBQDAABUkAFgQq1jNEZAAYEGsYjVHixUAAANUkABgQRSQ5ghIALAiEtIULVYAAAxQQQKABbGK1RwBCQAWxCpWc7RYAQAwYHO5XC5fTwK+53Q6lZKSouTkZNntdl9PB5UYf9ZwuSAgIUkqKChQcHCw8vPzFRQU5OvpoBLjzxouF7RYAQAwQEACAGCAgAQAwAABCUmS3W7XpEmTWDSBC44/a7hcsEgHAAADVJAAABggIAEAMEBAAgBggIAEAMAAAQnNmjVLV1xxhapVq6Z27dpp06ZNvp4SKqHMzEz16tVLkZGRstlsWrJkia+nBPwuAtLiFi5cqKSkJE2aNElfffWVWrdurdjYWB0+fNjXU0MlU1RUpNatW2vWrFm+ngpQLlzmYXHt2rXTTTfdpFdeeUWSVFZWpoYNG2rUqFF69NFHfTw7VFY2m02LFy9WXFycr6cCnBMVpIUVFxcrOztbMTEx7n1+fn6KiYlRVlaWD2cGAL5HQFrY0aNHVVpaqrCwMI/9YWFhcjgcPpoVAFwaCEgAAAwQkBZWr149+fv7Ky8vz2N/Xl6ewsPDfTQrALg0EJAWFhAQoKioKGVkZLj3lZWVKSMjQ9HR0T6cGQD4XhVfTwC+lZSUpPj4eLVt21Z//vOf9dJLL6moqEj333+/r6eGSqawsFB79uxxP963b59ycnIUEhKiRo0a+XBmgDEu84BeeeUVTZs2TQ6HQzfccINmzpypdu3a+XpaqGRWr16tTp06nbU/Pj5eqampF39CgAkCEgAAA3wGCQCAAQISAAADBCQAAAYISAAADBCQAAAYICABADBAQAIAYICABMpp8ODBHt9fePvtt2v06NEXfR6rV6+WzWbTiRMnLvrPBqyEgMRlb/DgwbLZbLLZbAoICFDTpk319NNP68yZMxf053700UeaMmVKucYSasDlh3uxolLo1q2b3nrrLTmdTn366adKSEhQ1apVlZyc7DGuuLhYAQEBXvmZISEhXjkPgEsTFSQqBbvdrvDwcDVu3FgjR45UTEyMli5d6m6L/uMf/1BkZKSaNWsmSdq/f7/69eun2rVrKyQkRL1799YPP/zgPl9paamSkpJUu3Zt1a1bV+PHj9f/3pXxf1usTqdTEyZMUMOGDWW329W0aVO9+eab+uGHH9z3IK1Tp45sNpsGDx4s6ZdvT0lJSVGTJk0UGBio1q1ba9GiRR4/59NPP9U111yjwMBAderUyWOeAC4cAhKVUmBgoIqLiyVJGRkZ2rVrl9LT05WWlqaSkhLFxsaqVq1a+vLLL7Vu3TrVrFlT3bp1cz/nxRdfVGpqqubOnau1a9fq2LFjWrx48e/+zEGDBum9997TzJkztWPHDv3rX/9SzZo11bBhQ3344YeSpF27dunQoUOaMWOGJCklJUVvv/225syZo+3bt2vMmDEaOHCg1qxZI+mXIO/Tp4969eqlnJwcDR06VI8++uiFetsA/DcXcJmLj4939e7d2+VyuVxlZWWu9PR0l91ud40dO9YVHx/vCgsLczmdTvf4d955x9WsWTNXWVmZe5/T6XQFBga6VqxY4XK5XK6IiAjX1KlT3cdLSkpcDRo0cP8cl8vluu2221wPP/ywy+VyuXbt2uWS5EpPTzec4xdffOGS5Dp+/Lh73+nTp13Vq1d3rV+/3mPskCFDXPfcc4/L5XK5kpOTXS1btvQ4PmHChLPOBcD7+AwSlUJaWppq1qypkpISlZWV6d5779XkyZOVkJCgVq1aeXzu+M0332jPnj2qVauWxzlOnz6tvXv3Kj8/X4cOHfL4yq8qVaqobdu2Z7VZf5WTkyN/f3/ddttt5Z7znj17dPLkSf3lL3/x2F9cXKw2bdpIknbs2HHWV4/xZdbAxUFAolLo1KmTXn31VQUEBCgyMlJVqvz2R7tGjRoeYwsLCxUVFaX58+efdZ769euf188PDAys8HMKCwslScuWLdOf/vQnj2N2u/285gHAewhIVAo1atRQ06ZNyzX2xhtv1MKFCxUaGqqgoCDDMREREdq4caM6duwoSTpz5oyys7N14403Go5v1aqVysrKtGbNGsXExJx1/NcKtrS01L2vZcuWstvtys3NPWfl2aJFCy1dutRj34YNG8xfJIA/jEU6sJwBAwaoXr166t27t7788kvt27dPq1ev1kMPPaQDBw5Ikh5++GE999xzWrJkiXbu3KkHH3zwd69hvOKKKxQfH68HHnhAS5YscZ/zgw8+kCQ1btxYNptNaWlpOnLkiAoLC1WrVi2NHTtWY8aM0bx587R371599dVXevnllzVv3jxJ0ogRI7R7926NGzdOu3bt0oIFC5Samnqh3yIAIiBhQdWrV1dmZqYaNWqkPn36qEWLFhoyZIhOnz7trigfeeQR3XfffYqPj1d0dLRq1aqlO++883fP++qrr+pvf/ubHnzwQTVv3lzDhg1TUVGRJOlPf/qTnnrqKT366KMKCwtTYmKiJGnKlCl68sknlZKSohYtWqhbt25atmyZmjRpIklq1KiRPvzwQy1ZskStW7fWnDlz9Oyzz17AdwfAr2yuc606AADAwqggAQAwQEACAGCAgAQAwAABCQCAAQISAAADBCQAAAYISAAADBCQAAAYICABADBAQAIAYICABADAAAEJAICB/wd+VUClJID6nQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(metrics['confusion_matrix'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
